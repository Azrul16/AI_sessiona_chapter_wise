{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Breast_cancer_data.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"diagnosis\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.iloc[:,:-1].corr(method=\"pearson\")\n",
    "cmap = sns.diverging_palette(250,354,80,60,center='dark',as_cmap=True)\n",
    "sns.heatmap(corr, vmax=1, vmin=-.5, cmap=cmap, square=True, linewidths=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"mean_radius\", \"mean_texture\", \"mean_smoothness\", \"diagnosis\"]]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.iloc[:,:-1].corr(method=\"pearson\")\n",
    "cmap = sns.diverging_palette(250,354,80,60,center='dark',as_cmap=True)\n",
    "sns.heatmap(corr, vmax=1, vmin=-.5, cmap=cmap, square=True, linewidths=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "sns.histplot(data, ax=axes[0], x=\"mean_radius\", kde=True, color='r')\n",
    "sns.histplot(data, ax=axes[1], x=\"mean_smoothness\", kde=True, color='b')\n",
    "sns.histplot(data, ax=axes[2], x=\"mean_texture\", kde=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate P(Y=y) for all possible y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior(df, Y):\n",
    "    classes = sorted(list(df[Y].unique()))\n",
    "    prior = []\n",
    "    for i in classes:\n",
    "        prior.append(len(df[df[Y]==i])/len(df))\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Calculate P(X=x|Y=y) using Gaussian dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood_gaussian(df, feat_name, feat_val, Y, label):\n",
    "    feat = list(df.columns)\n",
    "    df = df[df[Y]==label]\n",
    "    mean, std = df[feat_name].mean(), df[feat_name].std()\n",
    "    p_x_given_y = (1 / (np.sqrt(2 * np.pi) * std)) *  np.exp(-((feat_val-mean)**2 / (2 * std**2 )))\n",
    "    return p_x_given_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate P(X=x1|Y=y)P(X=x2|Y=y)...P(X=xn|Y=y) * P(Y=y) for all y and find the maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_gaussian(df, X, Y):\n",
    "    # get feature names\n",
    "    features = list(df.columns)[:-1]\n",
    "\n",
    "    # calculate prior\n",
    "    prior = calculate_prior(df, Y)\n",
    "\n",
    "    Y_pred = []\n",
    "    # loop over every data sample\n",
    "    for x in X:\n",
    "        # calculate likelihood\n",
    "        labels = sorted(list(df[Y].unique()))\n",
    "        likelihood = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            for i in range(len(features)):\n",
    "                likelihood[j] *= calculate_likelihood_gaussian(df, features[i], x[i], Y, labels[j])\n",
    "\n",
    "        # calculate posterior probability (numerator only)\n",
    "        post_prob = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            post_prob[j] = likelihood[j] * prior[j]\n",
    "\n",
    "        Y_pred.append(np.argmax(post_prob))\n",
    "\n",
    "    return np.array(Y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=.2, random_state=41)\n",
    "\n",
    "X_test = test.iloc[:,:-1].values\n",
    "Y_test = test.iloc[:,-1].values\n",
    "Y_pred = naive_bayes_gaussian(train, X=X_test, Y=\"diagnosis\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert continuous features to Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cat_mean_radius\"] = pd.cut(data[\"mean_radius\"].values, bins = 3, labels = [0,1,2])\n",
    "data[\"cat_mean_texture\"] = pd.cut(data[\"mean_texture\"].values, bins = 3, labels = [0,1,2])\n",
    "data[\"cat_mean_smoothness\"] = pd.cut(data[\"mean_smoothness\"].values, bins = 3, labels = [0,1,2])\n",
    "\n",
    "data = data.drop(columns=[\"mean_radius\", \"mean_texture\", \"mean_smoothness\"])\n",
    "data = data[[\"cat_mean_radius\",\t\"cat_mean_texture\",\t\"cat_mean_smoothness\", \"diagnosis\"]]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Calculate P(X=x|Y=y) categorically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood_categorical(df, feat_name, feat_val, Y, label):\n",
    "    feat = list(df.columns)\n",
    "    df = df[df[Y]==label]\n",
    "    p_x_given_y = len(df[df[feat_name]==feat_val]) / len(df)\n",
    "    return p_x_given_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate P(X=x1|Y=y)P(X=x2|Y=y)...P(X=xn|Y=y) * P(Y=y) for all y and find the maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_categorical(df, X, Y):\n",
    "    # get feature names\n",
    "    features = list(df.columns)[:-1]\n",
    "\n",
    "    # calculate prior\n",
    "    prior = calculate_prior(df, Y)\n",
    "\n",
    "    Y_pred = []\n",
    "    # loop over every data sample\n",
    "    for x in X:\n",
    "        # calculate likelihood\n",
    "        labels = sorted(list(df[Y].unique()))\n",
    "        likelihood = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            for i in range(len(features)):\n",
    "                likelihood[j] *= calculate_likelihood_categorical(df, features[i], x[i], Y, labels[j])\n",
    "\n",
    "        # calculate posterior probability (numerator only)\n",
    "        post_prob = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            post_prob[j] = likelihood[j] * prior[j]\n",
    "\n",
    "        Y_pred.append(np.argmax(post_prob))\n",
    "\n",
    "    return np.array(Y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Categorical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=.2, random_state=41)\n",
    "\n",
    "X_test = test.iloc[:,:-1].values\n",
    "Y_test = test.iloc[:,-1].values\n",
    "Y_pred = naive_bayes_categorical(train, X=X_test, Y=\"diagnosis\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "ebd20295ac1ad0fee94a1ca2cf9ed5bafd10fe9ef88accb34e917a787ce03399"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
